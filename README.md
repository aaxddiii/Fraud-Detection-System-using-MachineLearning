Fraud Detection System Using Machine Learning
Logistic Regression | Random Forest | XGBoost

This project is a Machine Learningâ€“based Fraud Detection System developed as part of our academic submission for JECRC University â€“ 7th Semester, CSE.
We compare three ML models:
Logistic Regression
Random Forest Classifier
XGBoost Classifier

To handle extreme class imbalance (0.17% fraud cases), we apply SMOTE oversampling.

ðŸ‘¥ Team Members
Name	                   Roll No
Darshan Jain	           22BCON533
Aaditya Mathur	         22BCON520
Deepak Kumar	           22BCON1383
Kriti Jain	             22BCON390

ðŸ“‚ Dataset
Kaggle â€“ Credit Card Fraud Detection Dataset
(284,807 transactions, 492 fraud cases)

Features:
V1 â€“ V28: PCA-transformed features
Time, Amount
Class: 0 = legitimate, 1 = fraud
Dataset is not included due to Kaggle policy.

ðŸ”§ Technology Stack
Python
Scikit-Learn
XGBoost
Pandas, NumPy
Imbalanced-Learn (SMOTE)
Matplotlib / Seaborn

ðŸ“Œ Project Workflow
Dataset â†’ Preprocessing â†’ Scaling â†’ SMOTE â†’ Train Models 
        â†’ Compare Metrics â†’ Best Model Output
        
ðŸ§  Models Implemented
âœ” Logistic Regression
Baseline linear classifier.
âœ” Random Forest
Ensemble trees â†’ good for non-linear patterns.
âœ” XGBoost (Best Performer)
Handles imbalanced data and captures complex relations.

ðŸ“ˆ Evaluation Metrics
Metric	   Logistic	  Random Forest  	XGBoost
Accuracy	  96â€“98%	     98â€“99%	       99%+
Precision	   0.92	        0.97	       0.99
Recall	     0.85	        0.95	       0.98
F1-score	   0.88	        0.96	       0.98
ROC-AUC	     0.97       	0.99	      >0.99

ðŸš€ XGBoost gives maximum recall â†’ best at catching fraud.
(Fewer false negatives = lower financial loss)
